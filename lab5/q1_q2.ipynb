{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.5087, 0.8307, 0.1934, 0.5939, 0.9351, 0.7018],\n",
      "        [0.2677, 0.3538, 0.8685, 0.1223, 0.0348, 0.9397],\n",
      "        [0.6791, 0.2936, 0.7550, 0.8957, 0.1346, 0.1151],\n",
      "        [0.7603, 0.1056, 0.5619, 0.9382, 0.2223, 0.6826],\n",
      "        [0.9518, 0.8505, 0.5871, 0.2871, 0.4171, 0.5726],\n",
      "        [0.3396, 0.6194, 0.0809, 0.9607, 0.7976, 0.3786]])\n",
      "tensor([[[[0.5087, 0.8307, 0.1934, 0.5939, 0.9351, 0.7018],\n",
      "          [0.2677, 0.3538, 0.8685, 0.1223, 0.0348, 0.9397],\n",
      "          [0.6791, 0.2936, 0.7550, 0.8957, 0.1346, 0.1151],\n",
      "          [0.7603, 0.1056, 0.5619, 0.9382, 0.2223, 0.6826],\n",
      "          [0.9518, 0.8505, 0.5871, 0.2871, 0.4171, 0.5726],\n",
      "          [0.3396, 0.6194, 0.0809, 0.9607, 0.7976, 0.3786]]]])\n",
      "kernel =  tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "kernel =  tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]]])\n",
      "outimage =  tensor([[[[4.7506, 4.9070, 4.5334, 4.4731],\n",
      "          [4.6456, 4.8946, 4.5334, 4.0853],\n",
      "          [5.5451, 5.2747, 4.7991, 4.2653],\n",
      "          [4.8572, 4.9914, 4.8530, 5.2569]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "image = torch.rand(6,6)\n",
    "print(\"image=\", image)\n",
    "\n",
    "image = image.unsqueeze(dim=0)\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(image)\n",
    "\n",
    "kernel = torch.ones(3,3)\n",
    "print(\"kernel = \", kernel)\n",
    "\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "print(\"kernel = \", kernel)\n",
    "\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=0)\n",
    "print(\"outimage = \", outimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= torch.Size([10, 10])\n",
      "image.shape= torch.Size([1, 10, 10])\n",
      "image.shape= torch.Size([1, 1, 10, 10])\n",
      "image= torch.Size([1, 1, 10, 10])\n",
      "kernel= torch.Size([3, 3])\n",
      "kernel= torch.Size([1, 1, 3, 3])\n",
      "outimage= torch.Size([1, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand(10,10)\n",
    "print(\"image=\", image.shape)\n",
    "\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "print(\"image=\", image.shape)\n",
    "\n",
    "kernel = torch.ones(3,3)\n",
    "print(\"kernel=\", kernel.shape)\n",
    "\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "print(\"kernel=\", kernel.shape)\n",
    "\n",
    "conv = torch.nn.Conv2d(1, 3, kernel_size=3)\n",
    "outimage = conv(image)\n",
    "print(\"outimage=\", outimage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dllab",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
